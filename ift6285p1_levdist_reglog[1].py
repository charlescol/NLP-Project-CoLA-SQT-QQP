# -*- coding: utf-8 -*-
"""ift6285p1_levdist/reglog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jZ4MTyNgB-Zk4OPtzNOFE1vTd3y9S__W
"""

import numpy as np
import pandas as pd
import csv
import jellyfish
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

train = pd.read_csv('msr_paraphrase_train.txt', sep = '\t', quoting=csv.QUOTE_NONE)
test = pd.read_csv('msr_paraphrase_test.txt', sep = '\t', quoting=csv.QUOTE_NONE)

n_train = train.shape[0]
n_test = test.shape[0]

X_train = []
X_test = []
y_train = []
y_test = []
for i in range(n_train):
  y_train.append(train.iloc[[i]]['Quality'].values[0])
  X_train.append(jellyfish.levenshtein_distance(train.iloc[[i]]['#1 String'].values[0], train.iloc[[i]]['#2 String'].values[0]))
for i in range(n_test):
  y_test.append(test.iloc[[i]]['Quality'].values[0])
  X_test.append(jellyfish.levenshtein_distance(test.iloc[[i]]['#1 String'].values[0], test.iloc[[i]]['#2 String'].values[0]))

d = {'X': X_train, 'y': y_train}
df = pd.DataFrame(data=d)

ax = sns.displot(df, x="X", hue="y", kind="kde", fill=True)
#plt.title("Distribution des distances Levenshtein sur l'ensemble d'entrainement")

clf = LogisticRegression(random_state=0).fit(np.array(X_train).reshape(-1, 1), y_train)

y_pred = clf.predict(np.array(X_test).reshape(-1, 1))

clf.score(np.array(X_test).reshape(-1, 1), y_test)

classification_report(y_test, y_pred)